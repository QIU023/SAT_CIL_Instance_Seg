/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:222: UserWarning: 'lat_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:222: UserWarning: 'pred_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:222: UserWarning: 'downsample_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
loading annotations into memory...
Done (t=0.30s)
creating index...
index created!
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
[0, 1, 2, 3] [64, 128, 320, 512]
[0, 1, 2, 3, 4, 5]
Initializing weights firstly...
Resuming training, loading weights/15-5/mix_transformer_7_7088_interrupt.pth...
Traceback (most recent call last):
  File "initial_train.py", line 592, in <module>
    train()
  File "initial_train.py", line 273, in train
    yolact_net.load_weights(args.resume)
  File "/opt/tiger/occupy_arnold/SATIS/yolact.py", line 780, in load_weights
    state_dict = torch.load(path)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 607, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 882, in _load
    result = unpickler.load()
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 857, in persistent_load
    load_tensor(data_type, size, key, _maybe_decode_ascii(location))
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 846, in load_tensor
    loaded_storages[key] = restore_location(storage, location)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 175, in default_restore_location
    result = fn(storage, location)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 157, in _cuda_deserialize
    return obj.cuda(device)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/_utils.py", line 79, in _cuda
    return new_type(self.size()).copy_(self, non_blocking)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/cuda/__init__.py", line 528, in _lazy_new
    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)
KeyboardInterrupt
Traceback (most recent call last):
  File "expert_train.py", line 67, in <module>
    help='The number of images to use for validation.')
  File "/usr/lib/python3.7/argparse.py", line 1376, in add_argument
    return self._add_action(action)
  File "/usr/lib/python3.7/argparse.py", line 1738, in _add_action
    if action.option_strings:
KeyboardInterrupt
/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:222: UserWarning: 'lat_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:222: UserWarning: 'pred_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:222: UserWarning: 'downsample_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
learning class: [16, 17, 18, 19, 20], previous learned class: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], remain: [] not learned!
loading annotations into memory...
Done (t=0.16s)
creating index...
index created!
learning class: [16, 17, 18, 19, 20], previous learned class: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], remain: [] not learned!
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
[0, 1, 2, 3] [64, 128, 320, 512]
[0, 1, 2, 3, 4, 5]
loading distillation net, loading weights/15-5/15-1_0_student_final.pth...
Traceback (most recent call last):
  File "incremental_train.py", line 666, in <module>
    train()
  File "incremental_train.py", line 286, in train
    yolact_sub_net.load_weights(args.load_distillation_net)
  File "/opt/tiger/occupy_arnold/SATIS/yolact.py", line 780, in load_weights
    state_dict = torch.load(path)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 607, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 882, in _load
    result = unpickler.load()
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 857, in persistent_load
    load_tensor(data_type, size, key, _maybe_decode_ascii(location))
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 846, in load_tensor
    loaded_storages[key] = restore_location(storage, location)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 175, in default_restore_location
    result = fn(storage, location)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/serialization.py", line 157, in _cuda_deserialize
    return obj.cuda(device)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/_utils.py", line 79, in _cuda
    return new_type(self.size()).copy_(self, non_blocking)
  File "/home/tiger/.local/lib/python3.7/site-packages/torch/cuda/__init__.py", line 528, in _lazy_new
    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)
KeyboardInterrupt
/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:235: UserWarning: 'downsample_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:235: UserWarning: 'lat_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
/home/tiger/.local/lib/python3.7/site-packages/torch/jit/_recursive.py:235: UserWarning: 'pred_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.
  " but it is a non-constant {}. Consider removing it.".format(name, hint))
total learned or learning class: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 
 incremental class: [16, 17, 18, 19, 20], 
 remain: [] not learned!
loading annotations into memory...
Done (t=0.14s)
creating index...
index created!
loading annotations into memory...
Done (t=0.03s)
creating index...
index created!
SAT_loss
[0, 1, 2, 3] [64, 128, 320, 512]
[0, 1, 2, 3, 4, 5]
loading distillation net, loading weights/15-5/15-5_0_student_final.pth...
SAT_loss
[0, 1, 2, 3] [64, 128, 320, 512]
[0, 1, 2, 3, 4, 5]
Initializing weights...
Begin training!

Traceback (most recent call last):
  File "incremental_train.py", line 870, in <module>
    train()
  File "incremental_train.py", line 616, in train
    for epoch in range(resume_epoch, num_epochs):
UnboundLocalError: local variable 'resume_epoch' referenced before assignment
usage: incremental_train.py [-h] [--batch_size BATCH_SIZE] [--step STEP]
                            [--task TASK] [--start_iter START_ITER]
                            [--num_workers NUM_WORKERS] [--cuda CUDA]
                            [--lr LR] [--distillation DISTILLATION]
                            [--load_distillation_net LOAD_DISTILLATION_NET]
                            [--resume RESUME]
                            [--load_expert_net LOAD_EXPERT_NET]
                            [--save_folder SAVE_FOLDER] [--momentum MOMENTUM]
                            [--decay DECAY] [--gamma GAMMA]
                            [--log_folder LOG_FOLDER] [--config CONFIG]
                            [--save_interval SAVE_INTERVAL]
                            [--validation_size VALIDATION_SIZE]
                            [--validation_epoch VALIDATION_EPOCH]
                            [--extend_class EXTEND_CLASS] [--keep_latest]
                            [--keep_latest_interval KEEP_LATEST_INTERVAL]
                            [--dataset DATASET] [--no_log] [--log_gpu]
                            [--no_interrupt] [--batch_alloc BATCH_ALLOC]
                            [--no_autoscale]
incremental_train.py: error: unrecognized arguments: /
total learned or learning class: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 
 incremental class: [16, 17, 18, 19, 20], 
 remain: [] not learned!
loading annotations into memory...
Done (t=0.15s)
creating index...
index created!
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
Traceback (most recent call last):
  File "incremental_train.py", line 879, in <module>
    train()
  File "incremental_train.py", line 447, in train
    yolact_sub_net = Yolact(sub=True)
  File "/opt/tiger/occupy_arnold/SAT_CIL_Instance_Seg/yolact.py", line 668, in __init__
    self.backbone = construct_backbone(cfg.backbone)
  File "/opt/tiger/occupy_arnold/SAT_CIL_Instance_Seg/backbone.py", line 454, in construct_backbone
    backbone = cfg.type(*cfg.args)
  File "/opt/tiger/occupy_arnold/SAT_CIL_Instance_Seg/modules/segformer_offical/mix_transformer.py", line 474, in __init__
    drop_rate=0.0, drop_path_rate=0.1, return_attn=return_attn)
  File "/opt/tiger/occupy_arnold/SAT_CIL_Instance_Seg/modules/segformer_offical/mix_transformer.py", line 301, in __init__
    for i in range(depths[3])])
  File "/opt/tiger/occupy_arnold/SAT_CIL_Instance_Seg/modules/segformer_offical/mix_transformer.py", line 301, in <listcomp>
    for i in range(depths[3])])
  File "/opt/tiger/occupy_arnold/SAT_CIL_Instance_Seg/modules/segformer_offical/mix_transformer.py", line 155, in __init__
    attn_drop=attn_drop, proj_drop=drop, sr_ratio=sr_ratio, return_attn=return_attn)
  File "/opt/tiger/occupy_arnold/SAT_CIL_Instance_Seg/modules/segformer_offical/mix_transformer.py", line 75, in __init__
    self.proj = nn.Linear(dim, dim)
  File "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py", line 90, in __init__
    self.reset_parameters()
  File "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py", line 96, in reset_parameters
    init.kaiming_uniform_(self.weight, a=math.sqrt(5))
  File "/usr/local/lib/python3.7/dist-packages/torch/nn/init.py", line 395, in kaiming_uniform_
    return tensor.uniform_(-bound, bound)
  File "/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py", line 129, in __exit__
    torch.set_grad_enabled(self.prev)
  File "/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py", line 213, in __init__
    def __init__(self, mode: bool) -> None:
KeyboardInterrupt
